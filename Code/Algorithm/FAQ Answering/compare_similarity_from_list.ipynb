{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compare similarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqWgT9rJU_Bc",
        "outputId": "9469dc11-7bc0-45ba-fd9b-a45b1ef97ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 9.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.63.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 55.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (3.10.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=ba731bdc942d051af3fab74e5e5070c66fb562d7cecacba86012395aee19cd69\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 sentence-transformers-2.2.0 sentencepiece-0.1.96 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "f=open('/content/covid_kaggle_answer_from_qa.json')\n",
        "data=json.load(f)"
      ],
      "metadata": {
        "id": "wGY9F1FoW4dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data['data']"
      ],
      "metadata": {
        "id": "WdCjfXPPWrm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findanswer(question):\n",
        "\n",
        "  sen =[]\n",
        "  sen.append(question)\n",
        "  for a in data:\n",
        "    for questions in a['questions']:\n",
        "      sen.append(questions['question'])  \n",
        "  model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "#Encoding:\n",
        "  sen_embeddings = model.encode(sen)\n",
        "  sen_embeddings.shape\n",
        "#let's calculate cosine similarity for sentence 0:\n",
        "  a=cosine_similarity(\n",
        "      [sen_embeddings[0]],\n",
        "      sen_embeddings[1:])\n",
        "  t=np.where(a==np.max(a))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "ekXkiDBRiAuV",
        "outputId": "f24ac21a-b06e-40e4-859a-2e4ed1b8bff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-136e095dbe77>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def main()\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO6CZAzAZ_Zh",
        "outputId": "de875446-ccd6-4925-ca60-f85c09769c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what causes 19-ncov.',\n",
              " 'Is the virus transmitted by aerisol, droplets, food, close contact, fecal matter, or water?',\n",
              " 'How long is the incubation period for the virus?',\n",
              " 'Can the virus be transmitted asymptomatically or during the incubation period?',\n",
              " 'How does weather, heat, and humidity affect the tramsmission of 2019-nCoV?',\n",
              " 'How long can the 2019-nCoV virus remain viable on common surfaces?',\n",
              " 'What risk factors contribute to the severity of 2019-nCoV?',\n",
              " 'How does hypertension affect patients?',\n",
              " 'How does heart disease affect patients?',\n",
              " 'How does copd affect patients?',\n",
              " 'How does smoking affect patients?',\n",
              " 'How does pregnancy affect patients?',\n",
              " 'What is the fatality rate of 2019-nCoV?',\n",
              " 'What public health policies prevent or control the spread of 2019-nCoV?',\n",
              " 'Can animals transmit 2019-nCoV?',\n",
              " 'What animal did 2019-nCoV come from?',\n",
              " 'What real-time genomic tracking tools exist?',\n",
              " 'What geographic variations are there in the genome of 2019-nCoV?',\n",
              " 'What effors are being done in asia to prevent further outbreaks?',\n",
              " 'What drugs or therapies are being investigated?',\n",
              " 'Are anti-inflammatory drugs recommended?',\n",
              " 'Which non-pharmaceutical interventions limit tramsission?',\n",
              " 'What are most important barriers to compliance?',\n",
              " 'How does extracorporeal membrane oxygenation affect 2019-nCoV patients?',\n",
              " 'What telemedicine and cybercare methods are most effective?',\n",
              " 'How is artificial intelligence being used in real time health delivery?',\n",
              " 'What adjunctive or supportive methods can help patients?',\n",
              " 'What diagnostic tests (tools) exist or are being developed to detect 2019-nCoV?',\n",
              " 'What is the immune system response to 2019-nCoV?',\n",
              " 'Can personal protective equipment prevent the transmission of 2019-nCoV?',\n",
              " 'Can 2019-nCoV infect patients a second time?']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sen = [\n",
        "#     \"what causes 19-ncov.\",\n",
        "#     \"What animal did 2019-nCoV come from?\",\n",
        "#     \"The person box was packed with jelly many dozens of months later.\",\n",
        "#     \"animals like me.\"\n",
        "# ]\n",
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "#Encoding:\n",
        "sen_embeddings = model.encode(sen)\n",
        "sen_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pWqtxXDVH7d",
        "outputId": "41e8c20a-a2c4-4f52-8624-2df69f8a07cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(sen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ9QoRMhcHjb",
        "outputId": "a40f7f03-32dc-4b9a-d46b-2bd372c1d625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "#let's calculate cosine similarity for sentence 0:\n",
        "a=cosine_similarity(\n",
        "    [sen_embeddings[0]],\n",
        "    sen_embeddings[1:]\n",
        ")"
      ],
      "metadata": {
        "id": "1l4qtp-fVu0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ln3wx4NidOaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t=np.where(a==np.max(a))\n",
        "\n"
      ],
      "metadata": {
        "id": "Q6HsdEQmWCj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen[t[1][0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SdZb4r5Tck-K",
        "outputId": "9fde5271-f265-4560-fe9a-380d0139148a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How long can the 2019-nCoV virus remain viable on common surfaces?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    }
  ]
}