{"cells":[{"cell_type":"markdown","metadata":{"id":"p3q-8OVotb0I"},"source":["# Covid19 Tweet Truth Analysis"]},{"cell_type":"markdown","metadata":{"id":"En6wNPErXsIZ"},"source":["late fusion version of 4 features:\n"," 1. tf-idf\n"," 2. word2vec\n"," 3. glove\n"," 4. fine-tuning Bert"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5718,"status":"ok","timestamp":1648429846691,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"},"user_tz":-480},"id":"Cggln2lMP_RL","outputId":"0b1f6af2-7d37-474e-be1e-4ccfbf5a484d"},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}],"source":["# setup CUDA\n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"eEYE4NDKaFG7"},"source":["# Data preprocess"]},{"cell_type":"markdown","metadata":{"id":"jJwJ4ubstb0M"},"source":["This dataset contains the training, validation, and test csv's, along with excel documents for the train and test files, a csv with the test file actual values, and ERNIE test results. For this analysis, I will be ignoring the excel files (as they are the same as the csv's) and the ERNIE results. I will be acting as if the test answer file did not exist for the duration of the testing phase as well, thus sticking with a basic approach of train, validate, see what the model decides for the tests."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3743,"status":"ok","timestamp":1648429943654,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"},"user_tz":-480},"id":"lltezbvMtb0N"},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import nltk #Natural Language Toolkit for Processing\n","from nltk.corpus import stopwords #Get the Stopwords to Remove\n","\n","import re #Regular Expressions\n","import html #Messing with HTML content, like &amp;\n","import string #String Processing\n","\n","import tensorflow as tf #Import tensorflow in order to use Keras\n","from tensorflow.keras.preprocessing.text import Tokenizer #Add the keras tokenizer for tweet tokenization\n","from tensorflow.keras.preprocessing.sequence import pad_sequences #Add padding to help the Keras Sequencing\n","import tensorflow.keras.layers as L #Import the layers as L for quicker typing\n","from tensorflow.keras.optimizers import Adam #Pull the adam optimizer for usage\n","\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy #Loss function being used\n","from sklearn.model_selection import train_test_split #Train Test Split"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":335,"status":"ok","timestamp":1648429945493,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"},"user_tz":-480},"id":"XJ2QygkDUIO0","outputId":"264df68a-2f8f-4f13-fbd7-600b95a43fb8"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["nltk.download('stopwords')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20350,"status":"ok","timestamp":1648429968240,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"},"user_tz":-480},"id":"7xxdx74d1qao","outputId":"74b6b83c-b1cf-4fa0-ad62-e50d06de7318"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]},{"output_type":"execute_result","data":{"text/plain":["['covid19-fake-news-dataset-nlp.zip',\n"," 'covid19-fake-news-dataset-nlp-unzip',\n"," 'BiLSTM.ipynb',\n"," 'bert',\n"," 'Transformer-Explainability',\n"," 'lqq_transformer1',\n"," 'lqq_transformer2',\n"," 'w2c-glove',\n"," 'Fake Detection.gdoc',\n"," 'late_fusion',\n"," 'tfidf',\n"," 'early_fusion',\n"," 'word2vec_tokenizer.pickle',\n"," 'glove_tokenizer.pickle']"]},"metadata":{},"execution_count":4}],"source":["import os\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","path = \"/content/gdrive/My Drive/PLP_sharing/project/fake_news\"\n","os.chdir(path)\n","os.listdir('./')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":743,"status":"ok","timestamp":1648429985963,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"},"user_tz":-480},"id":"E1bZMoXstb0O","outputId":"811ba959-a3f2-4965-d74e-deeb80422d17"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id                                              tweet label\n","0   1  The CDC currently reports 99031 deaths. In gen...  real\n","1   2  States reported 1121 deaths a small rise from ...  real\n","2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n","3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n","4   5  Populous states can generate large case counts...  real"],"text/html":["\n","  <div id=\"df-109785af-a819-45fa-9e26-29f0d024c14d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The CDC currently reports 99031 deaths. In gen...</td>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>States reported 1121 deaths a small rise from ...</td>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Populous states can generate large case counts...</td>\n","      <td>real</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-109785af-a819-45fa-9e26-29f0d024c14d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-109785af-a819-45fa-9e26-29f0d024c14d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-109785af-a819-45fa-9e26-29f0d024c14d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["twTrain = pd.read_csv(\"./covid19-fake-news-dataset-nlp-unzip/Constraint_Train.csv\") #Load the tweet (tw) training set\n","twTrain.head() #Take a peek at the data"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1648429988112,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"},"user_tz":-480},"id":"e8Ocx8pRtb0O","outputId":"c78b1a4c-8825-48df-d441-bc346c4d4884"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id                                              tweet label\n","0   1  Chinese converting to Islam after realising th...  fake\n","1   2  11 out of 13 people (from the Diamond Princess...  fake\n","2   3  COVID-19 Is Caused By A Bacterium, Not Virus A...  fake\n","3   4  Mike Pence in RNC speech praises Donald Trump’...  fake\n","4   5  6/10 Sky's @EdConwaySky explains the latest #C...  real"],"text/html":["\n","  <div id=\"df-ea39d7f7-a7c6-4681-8089-38fd774b8008\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Chinese converting to Islam after realising th...</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>11 out of 13 people (from the Diamond Princess...</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>COVID-19 Is Caused By A Bacterium, Not Virus A...</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Mike Pence in RNC speech praises Donald Trump’...</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>6/10 Sky's @EdConwaySky explains the latest #C...</td>\n","      <td>real</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea39d7f7-a7c6-4681-8089-38fd774b8008')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ea39d7f7-a7c6-4681-8089-38fd774b8008 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ea39d7f7-a7c6-4681-8089-38fd774b8008');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["twValid = pd.read_csv(\"./covid19-fake-news-dataset-nlp-unzip/Constraint_Val.csv\") #Load the tweet (tw) validation set\n","twValid.head() #Take a peek at the data"]},{"cell_type":"markdown","metadata":{"id":"7oe-NXlktb0Q"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"DBpRbiyytb0T"},"source":["## Clean Tweets"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":524,"status":"ok","timestamp":1648429990516,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"},"user_tz":-480},"id":"Ej1iVGeJtb0T","outputId":"55104a9c-b793-47cc-b9e5-3cecb92779bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n","['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"]}],"source":["punctuations = string.punctuation #List of punctuations to remove\n","print(punctuations) #See the punctuations the string library has\n","\n","STOP = stopwords.words(\"english\") #Get the NLTK stopwords\n","print(STOP) #See what NLTK considers stopwords"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1648429992350,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"},"user_tz":-480},"id":"9F5OD-vItb0T"},"outputs":[],"source":["def cleanTweets(tweetParse):\n","    for i in range(0,len(tweetParse)):\n","        tweet = tweetParse[i] #Putting the tweet into a variable so that it is not calling tweetParse[i] over and over\n","        tweet = html.unescape(tweet) #Removes leftover HTML elements, such as &amp;\n","        tweet = re.sub(r\"@\\w+\", \" \", tweet) #Completely removes @'s, as other peoples' usernames mean nothing\n","        tweet = re.sub(r\"http\\S+\", \" \", tweet) #Removes links, as links provide no data in tweet analysis in themselves\n","        \n","        tweet = \"\".join([punc for punc in tweet if not punc in punctuations]) #Removes the punctuation defined above\n","        tweet = tweet.lower() #Turning the tweets lowercase real quick for later use\n","    \n","        tweetWord = tweet.split() #Splits the tweet into individual words\n","        tweetParse[i] = \"\".join([word + \" \" for word in tweetWord if not word in STOP]) #Checks if the words are stop words\n","        \n","    return tweetParse #Returns the parsed tweets"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":883,"status":"ok","timestamp":1648429994770,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"},"user_tz":-480},"id":"iz2ar60ltb0U","outputId":"a54642b3-8b14-4a40-b261-84f405133be2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id                                              tweet label  \\\n","0   1  The CDC currently reports 99031 deaths. In gen...  real   \n","1   2  States reported 1121 deaths a small rise from ...  real   \n","2   3  Politically Correct Woman (Almost) Uses Pandem...  fake   \n","3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real   \n","4   5  Populous states can generate large case counts...  real   \n","\n","                                          cleanTweet  \n","0  cdc currently reports 99031 deaths general dis...  \n","1  states reported 1121 deaths small rise last tu...  \n","2  politically correct woman almost uses pandemic...  \n","3  indiafightscorona 1524 covid testing laborator...  \n","4  populous states generate large case counts loo...  "],"text/html":["\n","  <div id=\"df-e1592222-2e08-4990-ac59-e3ce88d25b0e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>label</th>\n","      <th>cleanTweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The CDC currently reports 99031 deaths. In gen...</td>\n","      <td>real</td>\n","      <td>cdc currently reports 99031 deaths general dis...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>States reported 1121 deaths a small rise from ...</td>\n","      <td>real</td>\n","      <td>states reported 1121 deaths small rise last tu...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n","      <td>fake</td>\n","      <td>politically correct woman almost uses pandemic...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n","      <td>real</td>\n","      <td>indiafightscorona 1524 covid testing laborator...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Populous states can generate large case counts...</td>\n","      <td>real</td>\n","      <td>populous states generate large case counts loo...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1592222-2e08-4990-ac59-e3ce88d25b0e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e1592222-2e08-4990-ac59-e3ce88d25b0e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e1592222-2e08-4990-ac59-e3ce88d25b0e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}],"source":["twTrain[\"cleanTweet\"] = cleanTweets(twTrain[\"tweet\"].copy()) #Clean the training tweets\n","twValid[\"cleanTweet\"] = cleanTweets(twValid[\"tweet\"].copy()) #Clean the validation tweets\n","\n","twTrain.head() #Take a look at the dataset"]},{"cell_type":"markdown","metadata":{"id":"S2HJFMVLtb0V"},"source":["## Label Encoding"]},{"cell_type":"markdown","metadata":{"id":"Oda6vRz1tb0V"},"source":["Interestingly, the get_dummies function in pandas will create encoded labels, since this is a binary classification problem. The real column created by it would have 1 for real and 0 for not real, which necessarily means fake in this case. That is the same as label encoding in this case."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":359,"status":"ok","timestamp":1648429998866,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"},"user_tz":-480},"id":"usM8xJQutb0V","outputId":"8da4c82f-25fc-4b54-96aa-ca78e54e542a"},"outputs":[{"output_type":"stream","name":"stdout","text":["      fake  real\n","0        0     1\n","1        0     1\n","2        1     0\n","3        0     1\n","4        0     1\n","...    ...   ...\n","6415     1     0\n","6416     1     0\n","6417     1     0\n","6418     1     0\n","6419     0     1\n","\n","[6420 rows x 2 columns]\n"]}],"source":["dummyTrain = pd.get_dummies(twTrain[\"label\"]) #Get the dummies for the training set\n","print(dummyTrain) #Show the dummies"]},{"cell_type":"markdown","metadata":{"id":"RmeDu9EKtb0V"},"source":["That real column shows the encoded values for real vs fake. I will be taking the real column as the encoded values."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1648430000866,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"},"user_tz":-480},"id":"BJ_egQH8tb0V","outputId":"f0e400f7-81d8-4bdf-d165-3dc442750bd6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id                                              tweet label  \\\n","0   1  The CDC currently reports 99031 deaths. In gen...  real   \n","1   2  States reported 1121 deaths a small rise from ...  real   \n","2   3  Politically Correct Woman (Almost) Uses Pandem...  fake   \n","3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real   \n","4   5  Populous states can generate large case counts...  real   \n","\n","                                          cleanTweet  encodedLabel  \n","0  cdc currently reports 99031 deaths general dis...             1  \n","1  states reported 1121 deaths small rise last tu...             1  \n","2  politically correct woman almost uses pandemic...             0  \n","3  indiafightscorona 1524 covid testing laborator...             1  \n","4  populous states generate large case counts loo...             1  "],"text/html":["\n","  <div id=\"df-62b47318-477e-4b5a-8d10-b24392c35cea\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>label</th>\n","      <th>cleanTweet</th>\n","      <th>encodedLabel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The CDC currently reports 99031 deaths. In gen...</td>\n","      <td>real</td>\n","      <td>cdc currently reports 99031 deaths general dis...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>States reported 1121 deaths a small rise from ...</td>\n","      <td>real</td>\n","      <td>states reported 1121 deaths small rise last tu...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n","      <td>fake</td>\n","      <td>politically correct woman almost uses pandemic...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n","      <td>real</td>\n","      <td>indiafightscorona 1524 covid testing laborator...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Populous states can generate large case counts...</td>\n","      <td>real</td>\n","      <td>populous states generate large case counts loo...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62b47318-477e-4b5a-8d10-b24392c35cea')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-62b47318-477e-4b5a-8d10-b24392c35cea button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-62b47318-477e-4b5a-8d10-b24392c35cea');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}],"source":["twTrain[\"encodedLabel\"] = dummyTrain[\"real\"].astype('int') #Get the encoded labels from the \"real\" dummies\n","twValid[\"encodedLabel\"] = pd.get_dummies(twValid[\"label\"])[\"real\"].astype('int') #Get the encoded labels for the validation set\n","\n","twTrain.head() #Take a peek at the data"]},{"cell_type":"code","source":["train_X = twTrain[\"cleanTweet\"]   # '0' refers to the review text\n","train_y = twTrain[\"encodedLabel\"]   # '1' corresponds to Label (1 - positive and 0 - negative)\n","test_X = twValid['cleanTweet']\n","test_y = twValid[\"encodedLabel\"]"],"metadata":{"id":"2uOsxGpSx75s","executionInfo":{"status":"ok","timestamp":1648430003164,"user_tz":-480,"elapsed":4,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U6DxqfwpLYx_"},"source":["# Model1: TF-IDF"]},{"cell_type":"code","source":["import pickle\n","\n","with open('./tfidf/tfidf.pickle', 'rb') as f:\n","    saved_tf_idf = pickle.load(f)\n","\n","with open('./tfidf/tfidf_lstm.pkl', 'rb') as f:\n","    saved_lstm = pickle.load(f)\n","\n","\n","test_text_fake = 'Alfalfa is the only cure for COVID-19.'\n","test_text_real = '#IndiaFightsCorona India has one of the lowest #COVID19 mortality globally with less than 2% Case Fatality Rate. As a result of supervised home isolation &amp; effective clinical treatment many States/UTs have CFR lower than the national average. https://t.co/QLiK8YPP7E'\n","\n","cleaned = cleanTweets([test_text_fake, test_text_real])\n","test_tfidf = saved_tf_idf.transform(cleaned).toarray()\n","x_test = test_tfidf.reshape(-1,1,200)\n","\n","print(x_test.shape, x_test.dtype)\n","\n","#0= Fake news\n","#1= Real news\n","preds = (saved_lstm.predict(x_test).ravel()>0.5)+0\n","for res in preds:\n","  if res==1:\n","    print(\"Real Covid News\")\n","  elif res==0:\n","    print(\"Fake Covid News\")\n","\n","print(preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cY9Z0jRsxSKs","executionInfo":{"status":"ok","timestamp":1648430043234,"user_tz":-480,"elapsed":23236,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"e2ff6061-e14a-496d-905e-919047fcd2a9"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 1, 200) float64\n","Fake Covid News\n","Real Covid News\n","[0 1]\n"]}]},{"cell_type":"code","source":["from sklearn import metrics\n","\n","cleaned = cleanTweets(test_X.values.tolist())\n","test_tfidf = saved_tf_idf.transform(cleaned).toarray()\n","x_test = test_tfidf.reshape(-1,1,200)\n","\n","y_pred = (saved_lstm.predict(x_test).ravel()>0.5)+0 # predict and get class (0 if pred < 0.5 else 1)\n","print(metrics.classification_report(test_y, y_pred, target_names=['Fake', 'Real']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8aSKiIjXxnEY","executionInfo":{"status":"ok","timestamp":1648374617757,"user_tz":-480,"elapsed":352,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"f6acde2e-c05c-49e0-d3b1-d9be7b73e23c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","        Fake       0.85      0.87      0.86      1020\n","        Real       0.88      0.86      0.87      1120\n","\n","    accuracy                           0.87      2140\n","   macro avg       0.87      0.87      0.87      2140\n","weighted avg       0.87      0.87      0.87      2140\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"V0tgpGD_9Bmo"},"source":["# Model2: Word2Vec"]},{"cell_type":"code","source":["!pip install gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G9CSfjQXFADm","executionInfo":{"status":"ok","timestamp":1648430046803,"user_tz":-480,"elapsed":3597,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"8c119b31-866b-4767-998c-258b9f420376"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n"]}]},{"cell_type":"code","source":["X_train_2 = twTrain[\"cleanTweet\"]   # '0' refers to the review text\n","y_train_2 = twTrain[\"encodedLabel\"]   # '1' corresponds to Label (1 - positive and 0 - negative)\n","X_test_2 = twValid['cleanTweet']\n","y_test_2 = twValid[\"encodedLabel\"]"],"metadata":{"id":"uevhMSdpFBhD","executionInfo":{"status":"ok","timestamp":1648430072076,"user_tz":-480,"elapsed":330,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from gensim.models import Word2Vec\n","\n","Embedding_dimensions = 200\n","\n","#Creating Word2Vec training dataset.\n","Word2vec_train_data = list(map(lambda x: x.split(), X_train_2))\n","\n","word2vec_model = Word2Vec(Word2vec_train_data,\n","                 size=Embedding_dimensions,\n","                 workers=8,\n","                 min_count=5)\n","\n","print(\"Vocabulary Length:\", len(word2vec_model.wv.vocab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZfF4f-zRFC-j","executionInfo":{"status":"ok","timestamp":1648430075588,"user_tz":-480,"elapsed":1926,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"60500f29-e9e4-4008-81f4-5606378e49b7"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary Length: 3181\n"]}]},{"cell_type":"code","source":["corpus = []\n","for i in range(0, len(X_train_2)):\n","  corpus.append(X_train_2[i])"],"metadata":{"id":"2kA86311FEOT","executionInfo":{"status":"ok","timestamp":1648430078286,"user_tz":-480,"elapsed":309,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from gensim.models import KeyedVectors\n","\n","input_length = 200\n","\n","tokenizer = Tokenizer(filters=\"\", lower=False, oov_token=\"<oov>\")\n","tokenizer.fit_on_texts(corpus)\n","\n","vocab_length = len(tokenizer.word_index) + 1\n","print(\"Tokenizer vocab length:\", vocab_length)\n","\n","X_train_2 = pad_sequences(tokenizer.texts_to_sequences(X_train_2), maxlen=input_length, dtype='float32')\n","X_test_2  = pad_sequences(tokenizer.texts_to_sequences(X_test_2) , maxlen=input_length, dtype='float32')\n","\n","print(\"X_train.shape:\", X_train_2.shape)\n","print(\"X_test.shape :\", X_test_2.shape)\n","\n","embedding_matrix = np.zeros((vocab_length, Embedding_dimensions))\n","for word, token in tokenizer.word_index.items():\n","  if word2vec_model.wv.__contains__(word):\n","      embedding_matrix[token] = word2vec_model.wv.__getitem__(word)\n","print(\"Embedding Matrix Shape:\", embedding_matrix.shape)   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cQVTkI-mFGVu","executionInfo":{"status":"ok","timestamp":1648430084275,"user_tz":-480,"elapsed":525,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"b99ced60-2934-44f6-a32f-ec9bee807f08"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizer vocab length: 16538\n","X_train.shape: (6420, 200)\n","X_test.shape : (2140, 200)\n","Embedding Matrix Shape: (16538, 200)\n"]}]},{"cell_type":"code","source":["# saving\n","with open('word2vec_tokenizer.pickle', 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"nLdtH2thTbhz","executionInfo":{"status":"ok","timestamp":1648430094727,"user_tz":-480,"elapsed":660,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["from keras.layers import Embedding\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout, GlobalMaxPool1D\n","\n","embedding_layer = Embedding(input_dim = vocab_length, \n","                                output_dim = Embedding_dimensions,\n","                                weights=[embedding_matrix], \n","                                input_length=input_length,\n","                                trainable=False)\n","base_model_2 = Sequential()\n","base_model_2.add(embedding_layer)\n","base_model_2.add(LSTM(128,return_sequences=True))\n","base_model_2.add(LSTM(64,return_sequences=True))\n","base_model_2.add(LSTM(32))\n","base_model_2.add(Dense(8, activation='relu'))\n","base_model_2.add(Dense(1, activation='sigmoid'))\n","base_model_2.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.001), metrics=['accuracy'])\n","base_model_2.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VLJ8xe7FHAi","executionInfo":{"status":"ok","timestamp":1648431122843,"user_tz":-480,"elapsed":1670,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"488246f6-08fd-4709-de1f-744375b0ebc8"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_3 (Embedding)     (None, 200, 200)          3307600   \n","                                                                 \n"," lstm_5 (LSTM)               (None, 200, 128)          168448    \n","                                                                 \n"," lstm_6 (LSTM)               (None, 200, 64)           49408     \n","                                                                 \n"," lstm_7 (LSTM)               (None, 32)                12416     \n","                                                                 \n"," dense_4 (Dense)             (None, 8)                 264       \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 9         \n","                                                                 \n","=================================================================\n","Total params: 3,538,145\n","Trainable params: 230,545\n","Non-trainable params: 3,307,600\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["d = base_model_2.fit(X_train_2, y_train_2, batch_size=64, epochs=10, verbose=1, validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8kVbdmrHFkPr","executionInfo":{"status":"ok","timestamp":1648431162061,"user_tz":-480,"elapsed":36550,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"75d31a78-0160-42d0-bc10-22a9bb95bdf8"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","81/81 [==============================] - 10s 53ms/step - loss: 0.5152 - accuracy: 0.7514 - val_loss: 0.4738 - val_accuracy: 0.7780\n","Epoch 2/10\n","81/81 [==============================] - 3s 36ms/step - loss: 0.4624 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7625\n","Epoch 3/10\n","81/81 [==============================] - 3s 36ms/step - loss: 0.4503 - accuracy: 0.7934 - val_loss: 0.4906 - val_accuracy: 0.7718\n","Epoch 4/10\n","81/81 [==============================] - 3s 36ms/step - loss: 0.4406 - accuracy: 0.7940 - val_loss: 0.4522 - val_accuracy: 0.7827\n","Epoch 5/10\n","81/81 [==============================] - 3s 37ms/step - loss: 0.4347 - accuracy: 0.7961 - val_loss: 0.4514 - val_accuracy: 0.7827\n","Epoch 6/10\n","81/81 [==============================] - 3s 36ms/step - loss: 0.4265 - accuracy: 0.8022 - val_loss: 0.4373 - val_accuracy: 0.7991\n","Epoch 7/10\n","81/81 [==============================] - 3s 37ms/step - loss: 0.4148 - accuracy: 0.8107 - val_loss: 0.4688 - val_accuracy: 0.7757\n","Epoch 8/10\n","81/81 [==============================] - 3s 36ms/step - loss: 0.4078 - accuracy: 0.8137 - val_loss: 0.4294 - val_accuracy: 0.7921\n","Epoch 9/10\n","81/81 [==============================] - 3s 37ms/step - loss: 0.4025 - accuracy: 0.8133 - val_loss: 0.4299 - val_accuracy: 0.8014\n","Epoch 10/10\n","81/81 [==============================] - 3s 36ms/step - loss: 0.3970 - accuracy: 0.8246 - val_loss: 0.4181 - val_accuracy: 0.8045\n"]}]},{"cell_type":"code","source":["pred=(base_model_2.predict(X_test_2) > 0.5).astype(\"int32\")"],"metadata":{"id":"tc5cRGgdFmEr","executionInfo":{"status":"ok","timestamp":1648431168110,"user_tz":-480,"elapsed":2777,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["from sklearn import metrics\n","\n","print(metrics.classification_report(y_test_2, pred, target_names=['Fake', 'Real']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fUhuqO_3YS0e","executionInfo":{"status":"ok","timestamp":1648431170120,"user_tz":-480,"elapsed":357,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"3b14a718-b713-4770-f07d-5bfd3f6c05ab"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","        Fake       0.77      0.85      0.81      1020\n","        Real       0.85      0.77      0.81      1120\n","\n","    accuracy                           0.81      2140\n","   macro avg       0.81      0.81      0.81      2140\n","weighted avg       0.81      0.81      0.81      2140\n","\n"]}]},{"cell_type":"code","source":["import pickle\n","# now you can save it to a file\n","with open('./late_fusion/word2vec.pkl', 'wb') as f:\n","    pickle.dump(base_model_2, f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VCCiassWHgOR","executionInfo":{"status":"ok","timestamp":1648380325624,"user_tz":-480,"elapsed":15869,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"2c59cb33-553d-4972-e275-cbeb6292a23c"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://7493baba-7ae0-4aeb-a9eb-afc44cabff69/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: ram://7493baba-7ae0-4aeb-a9eb-afc44cabff69/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f06df000cd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f06dee3ead0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f06dee3e8d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]}]},{"cell_type":"code","source":["with open('./late_fusion/word2vec.pkl', 'rb') as f:\n","    saved_base_model_2 = pickle.load(f)\n","\n","test_text_fake = 'Alfalfa is the only cure for COVID-19.'\n","test_text_real = '#IndiaFightsCorona India has one of the lowest #COVID19 mortality globally with less than 2% Case Fatality Rate. As a result of supervised home isolation &amp; effective clinical treatment many States/UTs have CFR lower than the national average. https://t.co/QLiK8YPP7E'\n","\n","test_input_2  = pad_sequences(tokenizer.texts_to_sequences([test_text_fake, test_text_real]) , maxlen=input_length, dtype='float32')\n","pred_test=(base_model_2.predict(test_input_2) > 0.5).astype(\"int32\")\n","pred_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qi9gfdiGH6fm","executionInfo":{"status":"ok","timestamp":1648380576566,"user_tz":-480,"elapsed":8475,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"e0d3e995-75fe-407e-c5ae-8ed63496b5f8"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0],\n","       [1]], dtype=int32)"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["# Model3: Glove"],"metadata":{"id":"XQoP_mCPw33A"}},{"cell_type":"code","source":["X_train_3 = twTrain[\"cleanTweet\"]   # '0' refers to the review text\n","y_train_3 = twTrain[\"encodedLabel\"]   # '1' corresponds to Label (1 - positive and 0 - negative)\n","X_test_3 = twValid['cleanTweet']\n","y_test_3 = twValid[\"encodedLabel\"]"],"metadata":{"id":"bdBi2AJxGYuq","executionInfo":{"status":"ok","timestamp":1648431178771,"user_tz":-480,"elapsed":350,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Maximum number of words to be embedded\n","NUM_WORDS = 30000\n","EMBEDDING_DIM=100\n","# max length to be encoded for a sentence\n","MAX_SEQUENCE_LENGTH = 200\n","\n","# Define Tokenize text function\n","tokenizer = Tokenizer(num_words=NUM_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'', lower=True)\n","# Fit the function on the text\n","tokenizer.fit_on_texts(X_train_3)\n","sequences = tokenizer.texts_to_sequences(X_train_3)\n","\n","# pad the data to the same length\n","data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n","\n","# Count number of unique tokens\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kCYboJHGGZAR","executionInfo":{"status":"ok","timestamp":1648431181448,"user_tz":-480,"elapsed":819,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"793e6022-0906-4c33-e0e7-2ba2db395335"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 16536 unique tokens.\n"]}]},{"cell_type":"code","source":["# saving tokenizer\n","with open('glove_tokenizer.pickle', 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"bGzZLImYUPNZ","executionInfo":{"status":"ok","timestamp":1648383563567,"user_tz":-480,"elapsed":3,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["word_vectors = dict()\n","\n","# load the whole embedding into memory\n","f = open('./w2c-glove/glove.6B.100d.txt', encoding=\"utf8\")\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    word_vectors[word] = coefs\n","f.close()\n","print('Loaded %s word vectors.' % len(word_vectors))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3o2IrJTTGdOG","executionInfo":{"status":"ok","timestamp":1648431200364,"user_tz":-480,"elapsed":10579,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"cca49bc7-4f06-45f6-d582-50fc41439a1f"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 400000 word vectors.\n"]}]},{"cell_type":"code","source":["vocabulary_size=min(len(word_index)+1,(NUM_WORDS))\n","#vocabulary_size= len(word_index)+1\n","embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n","\n","for word, i in word_index.items():\n","    if i>=NUM_WORDS:\n","        continue\n","    try:\n","        embedding_vector = word_vectors[word]\n","        embedding_matrix[i] = embedding_vector\n","    except KeyError:\n","      # if the word is not found, set to all 0s\n","        vec = np.zeros(EMBEDDING_DIM)\n","        embedding_matrix[i]=vec\n"],"metadata":{"id":"f9v56cyUGe_H","executionInfo":{"status":"ok","timestamp":1648431204155,"user_tz":-480,"elapsed":344,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["embedding_layer = Embedding(vocabulary_size,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            input_length=MAX_SEQUENCE_LENGTH,\n","                            trainable=False)"],"metadata":{"id":"dU1MocpHGgiJ","executionInfo":{"status":"ok","timestamp":1648431207079,"user_tz":-480,"elapsed":348,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Bidirectional, GlobalMaxPool1D\n","from keras.models import Sequential, Model\n","\n","inputs = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='float32')\n","embed_input = embedding_layer(inputs)\n","\n","x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(embed_input)\n","x = GlobalMaxPool1D()(x)\n","x = Dense(50, activation=\"relu\")(x)\n","x = Dropout(0.1)(x)\n","x = Dense(1, activation=\"sigmoid\")(x)\n","base_model_3 = Model(inputs=inputs,outputs=x)\n","base_model_3.summary() \n","\n","x3 = base_model_3.output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5MU8jImDGiEV","executionInfo":{"status":"ok","timestamp":1648431211552,"user_tz":-480,"elapsed":743,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"44ba7eb2-ba18-4534-ee79-474dfe676e11"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 200)]             0         \n","                                                                 \n"," embedding_4 (Embedding)     (None, 200, 100)          1653700   \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 200, 100)         60400     \n"," l)                                                              \n","                                                                 \n"," global_max_pooling1d_1 (Glo  (None, 100)              0         \n"," balMaxPooling1D)                                                \n","                                                                 \n"," dense_6 (Dense)             (None, 50)                5050      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 50)                0         \n","                                                                 \n"," dense_7 (Dense)             (None, 1)                 51        \n","                                                                 \n","=================================================================\n","Total params: 1,719,201\n","Trainable params: 65,501\n","Non-trainable params: 1,653,700\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["base_model_3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","history = base_model_3.fit(data, y_train_3, epochs=2, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjmhPbzGJ9YQ","executionInfo":{"status":"ok","timestamp":1648431908010,"user_tz":-480,"elapsed":688007,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"b56ed436-fcde-4d3f-ca63-1f09a2167923"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","201/201 [==============================] - 336s 2s/step - loss: 0.3863 - accuracy: 0.8316\n","Epoch 2/2\n","201/201 [==============================] - 323s 2s/step - loss: 0.2707 - accuracy: 0.8907\n"]}]},{"cell_type":"code","source":["from sklearn import metrics\n","\n","sequences = tokenizer.texts_to_sequences(X_test_3)\n","test_input_3 = pad_sequences(sequences, maxlen=200, padding='post')\n","pred= (base_model_3.predict(test_input_3) > 0.5).astype(\"int32\")\n","print(metrics.classification_report(y_test_3, pred, target_names=['Fake', 'Real']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FbCO1nTTHsyJ","executionInfo":{"status":"ok","timestamp":1648431999004,"user_tz":-480,"elapsed":8899,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"6b9acd93-f000-4cf6-e98b-72d643f86068"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","        Fake       0.86      0.91      0.89      1020\n","        Real       0.92      0.87      0.89      1120\n","\n","    accuracy                           0.89      2140\n","   macro avg       0.89      0.89      0.89      2140\n","weighted avg       0.89      0.89      0.89      2140\n","\n"]}]},{"cell_type":"code","source":["import pickle\n","# now you can save it to a file\n","with open('./late_fusion/glove.pkl', 'wb') as f:\n","    pickle.dump(base_model_3, f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mxk4TUbyKsrw","executionInfo":{"status":"ok","timestamp":1648432018989,"user_tz":-480,"elapsed":13034,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"8a1eddd6-3201-4165-ad97-36a63ebf3fd5"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://48000818-2f4f-4536-87b8-21ac990901c0/assets\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a75ce6b90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3aa5ad5650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]}]},{"cell_type":"code","source":["with open('./late_fusion/glove.pkl', 'rb') as f:\n","    saved_base_model_3 = pickle.load(f)\n","\n","test_text_fake = 'Alfalfa is the only cure for COVID-19.'\n","test_text_real = '#IndiaFightsCorona India has one of the lowest #COVID19 mortality globally with less than 2% Case Fatality Rate. As a result of supervised home isolation &amp; effective clinical treatment many States/UTs have CFR lower than the national average. https://t.co/QLiK8YPP7E'\n","\n","sequences = tokenizer.texts_to_sequences([test_text_fake, test_text_real])\n","test_input_3 = pad_sequences(sequences, maxlen=200, padding='post')\n","\n","pred_test=(saved_base_model_3.predict(test_input_3) > 0.5).astype(\"int32\")\n","pred_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gn3DsH4gKvMc","executionInfo":{"status":"ok","timestamp":1648382692001,"user_tz":-480,"elapsed":8204,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"1e002705-b9f5-45b5-c1a9-7d6ebb9c74c2"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0],\n","       [1]], dtype=int32)"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","metadata":{"id":"lwc7plXT9JHA"},"source":["# Model4: Bert"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26993,"status":"ok","timestamp":1648432172167,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"},"user_tz":-480},"id":"eZI9LBwX9MTe","outputId":"bcf8f92d-2bf8-46b9-aa6f-66f09a6e74e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 8.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 41.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.9 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 55.8 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 49.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n","Collecting azureml-core\n","  Downloading azureml_core-1.39.0.post1-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 8.8 MB/s \n","\u001b[?25hCollecting msal<2.0.0,>=1.15.0\n","  Downloading msal-1.17.0-py2.py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 7.4 MB/s \n","\u001b[?25hCollecting pathspec<1.0.0\n","  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n","Collecting argcomplete<2.0\n","  Downloading argcomplete-1.12.3-py2.py3-none-any.whl (38 kB)\n","Requirement already satisfied: contextlib2<22.0.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (0.5.5)\n","Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n","  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.5 MB/s \n","\u001b[?25hCollecting msal-extensions<0.4,>=0.3.0\n","  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\n","Collecting azure-mgmt-containerregistry<9.0.0,>=8.2.0\n","  Downloading azure_mgmt_containerregistry-8.2.0-py2.py3-none-any.whl (928 kB)\n","\u001b[K     |████████████████████████████████| 928 kB 41.2 MB/s \n","\u001b[?25hCollecting pkginfo\n","  Downloading pkginfo-1.8.2-py2.py3-none-any.whl (26 kB)\n","Collecting paramiko<3.0.0,>=2.0.8\n","  Downloading paramiko-2.10.3-py2.py3-none-any.whl (211 kB)\n","\u001b[K     |████████████████████████████████| 211 kB 60.6 MB/s \n","\u001b[?25hCollecting adal<=1.2.7,>=1.2.0\n","  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 3.6 MB/s \n","\u001b[?25hCollecting ndg-httpsclient<=0.5.1\n","  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n","Collecting backports.tempfile\n","  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n","Collecting azure-mgmt-storage<20.0.0,>=16.0.0\n","  Downloading azure_mgmt_storage-19.1.0-py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 56.8 MB/s \n","\u001b[?25hCollecting azure-common<2.0.0,>=1.1.12\n","  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n","Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0\n","  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 57.6 MB/s \n","\u001b[?25hCollecting azure-mgmt-keyvault<10.0.0,>=0.40.0\n","  Downloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\n","\u001b[K     |████████████████████████████████| 412 kB 54.1 MB/s \n","\u001b[?25hCollecting msrest<1.0.0,>=0.5.1\n","  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n","\u001b[K     |████████████████████████████████| 85 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging<22.0,>=20.0 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (21.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from azureml-core) (2018.9)\n","Collecting pyopenssl<22.0.0\n","  Downloading pyOpenSSL-21.0.0-py2.py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n","\u001b[?25hCollecting azure-core<1.22\n","  Downloading azure_core-1.21.1-py2.py3-none-any.whl (178 kB)\n","\u001b[K     |████████████████████████████████| 178 kB 48.7 MB/s \n","\u001b[?25hCollecting docker<6.0.0\n","  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n","\u001b[K     |████████████████████████████████| 146 kB 62.2 MB/s \n","\u001b[?25hCollecting azure-mgmt-resource<21.0.0,>=15.0.0\n","  Downloading azure_mgmt_resource-20.1.0-py3-none-any.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 44.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests[socks]<3.0.0,>=2.19.1 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (2.23.0)\n","Collecting jsonpickle<3.0.0\n","  Downloading jsonpickle-2.1.0-py2.py3-none-any.whl (38 kB)\n","Collecting humanfriendly<11.0,>=4.7\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.1 MB/s \n","\u001b[?25hCollecting PyJWT<3.0.0\n","  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n","Collecting knack~=0.9.0\n","  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3<=1.26.7,>=1.23 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (1.24.3)\n","Collecting jmespath<1.0.0\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting SecretStorage<4.0.0\n","  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from azureml-core) (2.8.2)\n","Collecting azure-graphrbac<1.0.0,>=0.40.0\n","  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n","\u001b[K     |████████████████████████████████| 141 kB 44.4 MB/s \n","\u001b[?25hCollecting msrestazure<=0.6.4,>=0.4.33\n","  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n","\u001b[K     |████████████████████████████████| 40 kB 5.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata<5,>=0.23 in /usr/local/lib/python3.7/dist-packages (from argcomplete<2.0->azureml-core) (4.11.3)\n","Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from azure-core<1.22->azureml-core) (1.15.0)\n","Collecting azure-mgmt-core<2.0.0,>=1.2.0\n","  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0->azureml-core) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0->azureml-core) (2.21)\n","Collecting websocket-client>=0.32.0\n","  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 1.1 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5,>=0.23->argcomplete<2.0->azureml-core) (3.7.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5,>=0.23->argcomplete<2.0->azureml-core) (3.10.0.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from knack~=0.9.0->azureml-core) (6.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from knack~=0.9.0->azureml-core) (0.8.9)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from knack~=0.9.0->azureml-core) (2.6.1)\n","Collecting portalocker<3,>=1.0\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Collecting isodate>=0.6.0\n","  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n","\u001b[K     |████████████████████████████████| 41 kB 633 kB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest<1.0.0,>=0.5.1->azureml-core) (1.3.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest<1.0.0,>=0.5.1->azureml-core) (2021.10.8)\n","Requirement already satisfied: pyasn1>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from ndg-httpsclient<=0.5.1->azureml-core) (0.4.8)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<22.0,>=20.0->azureml-core) (3.0.7)\n","Collecting pynacl>=1.0.1\n","  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n","\u001b[K     |████████████████████████████████| 856 kB 55.9 MB/s \n","\u001b[?25hCollecting bcrypt>=3.1.3\n","  Downloading bcrypt-3.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 474 kB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest<1.0.0,>=0.5.1->azureml-core) (3.2.0)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core) (1.7.1)\n","Collecting jeepney>=0.6\n","  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n","\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n","\u001b[?25hCollecting backports.weakref\n","  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n","Installing collected packages: PyJWT, isodate, cryptography, msrest, azure-core, adal, websocket-client, pyopenssl, pynacl, portalocker, msrestazure, msal, jmespath, jeepney, bcrypt, backports.weakref, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, ndg-httpsclient, msal-extensions, knack, jsonpickle, humanfriendly, docker, backports.tempfile, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, azureml-core\n","Successfully installed PyJWT-2.3.0 SecretStorage-3.3.1 adal-1.2.7 argcomplete-1.12.3 azure-common-1.1.28 azure-core-1.21.1 azure-graphrbac-0.61.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-8.2.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.3.0 azure-mgmt-resource-20.1.0 azure-mgmt-storage-19.1.0 azureml-core-1.39.0.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.2.0 cryptography-36.0.2 docker-5.0.3 humanfriendly-10.0 isodate-0.6.1 jeepney-0.7.1 jmespath-0.10.0 jsonpickle-2.1.0 knack-0.9.0 msal-1.17.0 msal-extensions-0.3.1 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 paramiko-2.10.3 pathspec-0.9.0 pkginfo-1.8.2 portalocker-2.4.0 pynacl-1.5.0 pyopenssl-21.0.0 websocket-client-1.3.1\n"]}],"source":["!pip install transformers\n","!pip install azureml-core"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":6697,"status":"ok","timestamp":1648382798589,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"},"user_tz":-480},"id":"Kdp1PgCFwEMX"},"outputs":[],"source":["import torch\n","\n","base_model_4 = torch.load('./lqq_transformer1/model')"]},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","test_text_fake = 'Alfalfa is the only cure for COVID-19.'\n","test_text_real = '#IndiaFightsCorona India has one of the lowest #COVID19 mortality globally with less than 2% Case Fatality Rate. As a result of supervised home isolation &amp; effective clinical treatment many States/UTs have CFR lower than the national average. https://t.co/QLiK8YPP7E'\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","test_text = tokenizer(list([test_text_fake, test_text_real]), \n","                          max_length = 128,           # Pad & truncate all sentences.\n","                          padding = 'max_length',\n","                          truncation=True,\n","                          return_attention_mask = True,   # Construct attn. masks.\n","                          return_tensors = 'pt'     # Return pytorch tensors.\n",")\n","test_seq = torch.tensor(test_text['input_ids']).to('cuda:0')\n","test_mask = torch.tensor(test_text['attention_mask']).to('cuda:0')\n","\n","with torch.no_grad():\n","  outputs = base_model_4(test_seq, test_mask) # reference: https://www.kaggle.com/akshat0007/bert-for-sequence-classification\n","  pred_proba = outputs[0].detach().cpu().numpy()\n","\n","preds = np.argmax(pred_proba, axis = 1)\n","\n","print([preds.tolist(), pred_proba.tolist()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bl6Dh0p3zMFs","executionInfo":{"status":"ok","timestamp":1648377148416,"user_tz":-480,"elapsed":1737,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"e2e7f5fe-ded0-4150-bbfa-c94477af8d3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0, 1], [[0.6307932734489441, -0.8636711239814758], [-2.8603923320770264, 2.058260202407837]]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  from ipykernel import kernelapp as app\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  app.launch_new_instance()\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","test_text = tokenizer(list(test_X.values.tolist()), \n","                          max_length = 128,           # Pad & truncate all sentences.\n","                          padding = 'max_length',\n","                          truncation=True,\n","                          return_attention_mask = True,   # Construct attn. masks.\n","                          return_tensors = 'pt'     # Return pytorch tensors.\n",")\n","# val_dataset = TensorDataset(encoded_textsValid['input_ids'], encoded_textsValid['attention_mask'], labelsValid)\n","test_seq = torch.tensor(test_text['input_ids']).to('cuda:0')\n","test_mask = torch.tensor(test_text['attention_mask']).to('cuda:0')\n","\n","with torch.no_grad():\n","  outputs = base_model_4(test_seq, test_mask) # reference: https://www.kaggle.com/akshat0007/bert-for-sequence-classification\n","  pred_proba = outputs[0].detach().cpu().numpy()\n","\n","preds = np.argmax(pred_proba, axis = 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5LFI4DC80H7t","executionInfo":{"status":"ok","timestamp":1648377177268,"user_tz":-480,"elapsed":11066,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"ef975978-957a-4e80-b0e5-ec0ce5957ab0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  if sys.path[0] == '':\n"]}]},{"cell_type":"code","source":["from sklearn import metrics\n","print(metrics.classification_report(test_y, preds, target_names=['Fake', 'Real']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A76Q8G9J768K","executionInfo":{"status":"ok","timestamp":1648377219298,"user_tz":-480,"elapsed":332,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"ca937269-c672-4313-bd64-b54da46aa41f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","        Fake       0.91      0.95      0.93      1020\n","        Real       0.95      0.92      0.94      1120\n","\n","    accuracy                           0.93      2140\n","   macro avg       0.93      0.93      0.93      2140\n","weighted avg       0.93      0.93      0.93      2140\n","\n"]}]},{"cell_type":"markdown","source":["# Do Ensemble"],"metadata":{"id":"amqWrnaf0h5D"}},{"cell_type":"code","source":["from transformers import BertTokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import torch\n","\n","# loading models\n","# Model 1\n","with open('./tfidf/tfidf.pickle', 'rb') as f:\n","    saved_tf_idf = pickle.load(f)\n","with open('./tfidf/tfidf_lstm.pkl', 'rb') as f:\n","    saved_lstm = pickle.load(f)\n","# Model 2\n","with open('word2vec_tokenizer.pickle', 'rb') as handle:\n","    tokenizer_2 = pickle.load(handle)\n","with open('./late_fusion/word2vec.pkl', 'rb') as f:\n","    saved_base_model_2 = pickle.load(f)\n","# Model 3\n","with open('glove_tokenizer.pickle', 'rb') as handle:\n","    tokenizer_3 = pickle.load(handle)\n","with open('./late_fusion/glove.pkl', 'rb') as f:\n","    saved_base_model_3 = pickle.load(f)\n","# Model 4\n","saved_base_model_4 = torch.load('./lqq_transformer1/model')\n","\n","\n","\n","test_text_fake = 'Alfalfa is the only cure for COVID-19.'\n","\n","# Model 1\n","cleaned = cleanTweets(test_X.values.tolist())\n","test_tfidf = saved_tf_idf.transform(cleaned).toarray().reshape(-1,1,200)\n","preds_1 = (saved_lstm.predict(test_tfidf).ravel()>0.5)+0\n","\n","\n","# Model 2\n","test_input_2  = pad_sequences(tokenizer_2.texts_to_sequences(test_X) , maxlen=input_length, dtype='float32')\n","preds_2=(saved_base_model_2.predict(test_input_2) > 0.5).astype(\"int32\")\n","\n","# Model 3\n","test_input_3 = pad_sequences(tokenizer_3.texts_to_sequences(test_X), maxlen=200, padding='post')\n","preds_3 = (saved_base_model_3.predict(test_input_3) > 0.5).astype(\"int32\")\n","\n","# Model 4\n","tokenizer  = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","test_text = tokenizer(test_X.values.tolist(), \n","                          max_length = 128,           # Pad & truncate all sentences.\n","                          padding = 'max_length',\n","                          truncation=True,\n","                          return_attention_mask = True,   # Construct attn. masks.\n","                          return_tensors = 'pt'     # Return pytorch tensors.\n",")\n","test_seq = torch.tensor(test_text['input_ids']).to('cuda:0')\n","test_mask = torch.tensor(test_text['attention_mask']).to('cuda:0')\n","\n","with torch.no_grad():\n","  outputs = saved_base_model_4(test_seq, test_mask) # reference: https://www.kaggle.com/akshat0007/bert-for-sequence-classification\n","  pred_proba = outputs[0].detach().cpu().numpy()\n","\n","preds_4 = np.argmax(pred_proba, axis = 1)\n","\n","\n","# Do voting\n","final_predict = [int(preds_1[i] * 0.2 + preds_2[i][0] * 0.1 + preds_3[i][0] * 0.3 + preds_4[i] * 0.4) for i in range(len(preds_4))]\n","# print(final_predict)\n","\n","from sklearn import metrics\n","print(metrics.classification_report(test_y, final_predict, target_names=['Fake', 'Real']))"],"metadata":{"id":"yo4JnN7Z0knt","colab":{"base_uri":"https://localhost:8080/","height":428,"referenced_widgets":["90d62394791243b392e12217963c27d6","4dd3e4b07fa84c81a7cf5696a32aeebc","badb56d9069a450da1cd0581b85b9b84","8860818400094c938df41349c824028b","1c31e4c63bfa4dcfaeb88935c97313be","4caeb5e06cd549a49427a4f625646fc8","45975ce641d7498abf5a52d081a37c7d","ef3a1037b5194b56b4968fce313adac1","ccf74bb408354d02ad5d32b7cd51813b","b5b9a0c1bd6b416a84daf1d3367f305b","94cb74f963d8481e80dc478c82525e4f","9d9fdb4e7c8a4719ac2a64fffa5a4d3e","942f9a0ef9ac445ba698a11576d38552","9ede0bfcf8ef49b2b62a0d478d660744","56356653293d44148c9b13f5a85f4fee","cc3e61b9606c4b0e8b7b0d18a3069bb9","2578085c5e764b2aa4423a94b6ddbe22","2cf785edae644e89bf2ed6a233f6bbb5","9bc5a425752a46e2853caab0f59bca74","16bb0311c6dd4ae0b74b1371b3b0ecdb","5c76b40940db4e47a9da88ff82e22abc","ddfcd3a050cc404aa721c7616675ab66","ad76f0567f684fccba0bd41aefdb24e9","b2227e89151a40268d9e3fc014c99ad9","ae51b78fa0bf437db49f44ca2d262596","4d556fea1139403ab350ee5cd1797e5e","26419c29b94e4f43b7a800a370a7e723","706b6b02eb42477da17f44cd866a1e22","f8000de43c7f494a84622d0e1a8d7054","1da297bfbab94670aeb7308762faafde","087618a90e0f4cec82f8a8c8ceafb175","6b74c68905de4666a91920c322cc29b2","c05e14f68fb84f968c7cb510b6c7ec9c"]},"executionInfo":{"status":"ok","timestamp":1648432467623,"user_tz":-480,"elapsed":49682,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"2ad752ed-4b0f-4a65-d39d-b2d1f7641d66"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90d62394791243b392e12217963c27d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d9fdb4e7c8a4719ac2a64fffa5a4d3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad76f0567f684fccba0bd41aefdb24e9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","        Fake       0.75      0.99      0.85      1020\n","        Real       0.99      0.70      0.82      1120\n","\n","    accuracy                           0.84      2140\n","   macro avg       0.87      0.85      0.84      2140\n","weighted avg       0.87      0.84      0.84      2140\n","\n"]}]},{"cell_type":"markdown","source":["# Conclution\n","\n","The experiment result is as follows.\n","\n","| Models   | Accuracy | Details |\n","|----------|----------|---------|\n","| TF-IDF   | 0.87     |         |\n","| Word2Vec | 0.81     |         |\n","| Glove    | 0.89     |         |\n","|Fine-tune BERT| 0.94 |         |\n","|Late fusion| 0.85 |         |\n","|Early fusion| 0.78 |         |"],"metadata":{"id":"kAZiocRvLSD6"}},{"cell_type":"code","source":["# Do voting\n","final_predict = [int(preds_1[i] * 0.1 + preds_2[i][0] * 0 + preds_3[i][0] * 0.1 + preds_4[i] * 0.8) for i in range(len(preds_4))]\n","# print(final_predict)\n","\n","from sklearn import metrics\n","print(metrics.classification_report(test_y, final_predict, target_names=['Fake', 'Real']))"],"metadata":{"id":"0Ued6AT1PgKi","executionInfo":{"status":"ok","timestamp":1648432661293,"user_tz":-480,"elapsed":335,"user":{"displayName":"Lin Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08380508212158643579"}},"outputId":"1a359ab6-000a-4fc9-f0db-3088c1c069cf","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","        Fake       0.80      0.98      0.88      1020\n","        Real       0.98      0.78      0.87      1120\n","\n","    accuracy                           0.87      2140\n","   macro avg       0.89      0.88      0.87      2140\n","weighted avg       0.89      0.87      0.87      2140\n","\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"05_late_fusion_ensemble.ipynb","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"90d62394791243b392e12217963c27d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4dd3e4b07fa84c81a7cf5696a32aeebc","IPY_MODEL_badb56d9069a450da1cd0581b85b9b84","IPY_MODEL_8860818400094c938df41349c824028b"],"layout":"IPY_MODEL_1c31e4c63bfa4dcfaeb88935c97313be"}},"4dd3e4b07fa84c81a7cf5696a32aeebc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4caeb5e06cd549a49427a4f625646fc8","placeholder":"​","style":"IPY_MODEL_45975ce641d7498abf5a52d081a37c7d","value":"Downloading: 100%"}},"badb56d9069a450da1cd0581b85b9b84":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef3a1037b5194b56b4968fce313adac1","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ccf74bb408354d02ad5d32b7cd51813b","value":231508}},"8860818400094c938df41349c824028b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5b9a0c1bd6b416a84daf1d3367f305b","placeholder":"​","style":"IPY_MODEL_94cb74f963d8481e80dc478c82525e4f","value":" 226k/226k [00:00&lt;00:00, 880kB/s]"}},"1c31e4c63bfa4dcfaeb88935c97313be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4caeb5e06cd549a49427a4f625646fc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45975ce641d7498abf5a52d081a37c7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef3a1037b5194b56b4968fce313adac1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccf74bb408354d02ad5d32b7cd51813b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5b9a0c1bd6b416a84daf1d3367f305b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94cb74f963d8481e80dc478c82525e4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d9fdb4e7c8a4719ac2a64fffa5a4d3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_942f9a0ef9ac445ba698a11576d38552","IPY_MODEL_9ede0bfcf8ef49b2b62a0d478d660744","IPY_MODEL_56356653293d44148c9b13f5a85f4fee"],"layout":"IPY_MODEL_cc3e61b9606c4b0e8b7b0d18a3069bb9"}},"942f9a0ef9ac445ba698a11576d38552":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2578085c5e764b2aa4423a94b6ddbe22","placeholder":"​","style":"IPY_MODEL_2cf785edae644e89bf2ed6a233f6bbb5","value":"Downloading: 100%"}},"9ede0bfcf8ef49b2b62a0d478d660744":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bc5a425752a46e2853caab0f59bca74","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16bb0311c6dd4ae0b74b1371b3b0ecdb","value":28}},"56356653293d44148c9b13f5a85f4fee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c76b40940db4e47a9da88ff82e22abc","placeholder":"​","style":"IPY_MODEL_ddfcd3a050cc404aa721c7616675ab66","value":" 28.0/28.0 [00:00&lt;00:00, 877B/s]"}},"cc3e61b9606c4b0e8b7b0d18a3069bb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2578085c5e764b2aa4423a94b6ddbe22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cf785edae644e89bf2ed6a233f6bbb5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bc5a425752a46e2853caab0f59bca74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16bb0311c6dd4ae0b74b1371b3b0ecdb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c76b40940db4e47a9da88ff82e22abc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddfcd3a050cc404aa721c7616675ab66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad76f0567f684fccba0bd41aefdb24e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2227e89151a40268d9e3fc014c99ad9","IPY_MODEL_ae51b78fa0bf437db49f44ca2d262596","IPY_MODEL_4d556fea1139403ab350ee5cd1797e5e"],"layout":"IPY_MODEL_26419c29b94e4f43b7a800a370a7e723"}},"b2227e89151a40268d9e3fc014c99ad9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_706b6b02eb42477da17f44cd866a1e22","placeholder":"​","style":"IPY_MODEL_f8000de43c7f494a84622d0e1a8d7054","value":"Downloading: 100%"}},"ae51b78fa0bf437db49f44ca2d262596":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1da297bfbab94670aeb7308762faafde","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_087618a90e0f4cec82f8a8c8ceafb175","value":570}},"4d556fea1139403ab350ee5cd1797e5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b74c68905de4666a91920c322cc29b2","placeholder":"​","style":"IPY_MODEL_c05e14f68fb84f968c7cb510b6c7ec9c","value":" 570/570 [00:00&lt;00:00, 16.7kB/s]"}},"26419c29b94e4f43b7a800a370a7e723":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"706b6b02eb42477da17f44cd866a1e22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8000de43c7f494a84622d0e1a8d7054":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1da297bfbab94670aeb7308762faafde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"087618a90e0f4cec82f8a8c8ceafb175":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b74c68905de4666a91920c322cc29b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c05e14f68fb84f968c7cb510b6c7ec9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}